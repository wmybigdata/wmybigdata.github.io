<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Hive高级进阶, java,jvm,hadoop,flink,hive,kafka,spark,hbase,clickhose,linux,superset等">
    <meta name="description" content="本网站是个人兴趣爱好，总结分享经验，记录生活点滴的平台，希望在以后的学习旅途中，走出自己的风景。">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Hive高级进阶 | 情深骚明大数据之旅</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 4.2.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="stylesheet" href="/css/prism-tomorrow.css" type="text/css">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>



<script src="/js/FunnyTitle.js"></script>
<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">情深骚明大数据之旅</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">情深骚明大数据之旅</div>
        <div class="logo-desc">
            
            本网站是个人兴趣爱好，总结分享经验，记录生活点滴的平台，希望在以后的学习旅途中，走出自己的风景。
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/blinkfox/hexo-theme-matery" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/blinkfox/hexo-theme-matery" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/10.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Hive高级进阶</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/hive/">
                                <span class="chip bg-color">hive</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/hive/" class="post-category">
                                hive
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-08-23
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Hive高级优化"><a href="#Hive高级优化" class="headerlink" title="Hive高级优化"></a>Hive高级优化</h1><h2 id="第-1-章-Explain-查看执行计划（重点）"><a href="#第-1-章-Explain-查看执行计划（重点）" class="headerlink" title="第 1 章 Explain 查看执行计划（重点）"></a>第 1 章 Explain 查看执行计划（重点）</h2><h3 id="1-1-创建测试用表"><a href="#1-1-创建测试用表" class="headerlink" title="1.1  创建测试用表"></a>1.1  创建测试用表</h3><h4 id="1）建大表、小表和-JOIN-后表的语句"><a href="#1）建大表、小表和-JOIN-后表的语句" class="headerlink" title="1）建大表、小表和 JOIN 后表的语句"></a>1）建大表、小表和 JOIN 后表的语句</h4><pre class=" language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">// 创建大表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> bigtable
             <span class="token punctuation">(</span>
                          id <span class="token keyword">bigint</span>
                        <span class="token punctuation">,</span> t  <span class="token keyword">bigint</span>
                        <span class="token punctuation">,</span> uid string
                        <span class="token punctuation">,</span> keyword string
                        <span class="token punctuation">,</span> url_rank  <span class="token keyword">int</span>
                        <span class="token punctuation">,</span> click_num <span class="token keyword">int</span>
                        <span class="token punctuation">,</span> click_url string
             <span class="token punctuation">)</span>
             <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span>
<span class="token punctuation">;</span>



<span class="token comment" spellcheck="true">// 创建小表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> smalltable
             <span class="token punctuation">(</span>
                          id <span class="token keyword">bigint</span>
                        <span class="token punctuation">,</span> t  <span class="token keyword">bigint</span>
                        <span class="token punctuation">,</span> uid string
                        <span class="token punctuation">,</span> keyword string
                        <span class="token punctuation">,</span> url_rank  <span class="token keyword">int</span>
                        <span class="token punctuation">,</span> click_num <span class="token keyword">int</span>
                        <span class="token punctuation">,</span> click_url string
             <span class="token punctuation">)</span>
             <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span>
<span class="token punctuation">;</span>



<span class="token comment" spellcheck="true">// 创建 JOIN 后表</span>
<span class="token keyword">create</span> <span class="token keyword">table</span> jointable
             <span class="token punctuation">(</span>
                          id <span class="token keyword">bigint</span>
                        <span class="token punctuation">,</span> t  <span class="token keyword">bigint</span>
                        <span class="token punctuation">,</span> uid string
                        <span class="token punctuation">,</span> keyword string
                        <span class="token punctuation">,</span> url_rank  <span class="token keyword">int</span>
                        <span class="token punctuation">,</span> click_num <span class="token keyword">int</span>
                        <span class="token punctuation">,</span> click_url string
             <span class="token punctuation">)</span>
             <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span>
<span class="token punctuation">;</span>
</code></pre>
<h4 id="2）分别向大表和小表中导入数据"><a href="#2）分别向大表和小表中导入数据" class="headerlink" title="2）分别向大表和小表中导入数据"></a>2）分别向大表和小表中导入数据</h4><pre class=" language-properties"><code class="language-properties"><span class="token attr-name">load</span> <span class="token attr-value">data local inpath '/opt/flink/hive/data/bigtable' into table bigtable;</span>
<span class="token attr-name">load</span> <span class="token attr-value">data local inpath '/opt/flink/hive/data/smalltable' into table smalltable;</span>
</code></pre>
<h3 id="1-2-基本语法"><a href="#1-2-基本语法" class="headerlink" title="1.2 基本语法"></a>1.2 基本语法</h3><pre class=" language-sql"><code class="language-sql"><span class="token keyword">EXPLAIN</span> <span class="token punctuation">[</span><span class="token keyword">EXTENDED</span> <span class="token operator">|</span> DEPENDENCY <span class="token operator">|</span> <span class="token keyword">AUTHORIZATION</span><span class="token punctuation">]</span> query<span class="token operator">-</span>sql
</code></pre>
<h3 id="1-3-案例实操"><a href="#1-3-案例实操" class="headerlink" title="1.3 案例实操"></a>1.3 案例实操</h3><h4 id="1）查看下面这条语句的执行计划"><a href="#1）查看下面这条语句的执行计划" class="headerlink" title="1）查看下面这条语句的执行计划"></a>1）查看下面这条语句的执行计划</h4><pre class=" language-sql"><code class="language-sql"><span class="token keyword">explain</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> bigtable<span class="token punctuation">;</span>
<span class="token keyword">explain</span> <span class="token keyword">select</span> click_url<span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> ct <span class="token keyword">from</span> bigtable <span class="token keyword">group</span> <span class="token keyword">by</span> click_url<span class="token punctuation">;</span>
</code></pre>
<pre class=" language-properties"><code class="language-properties"><span class="token attr-name">hive</span> <span class="token attr-value">(wmy)> explain select * from bigtable;</span>
OK
Explain
<span class="token attr-name">STAGE</span> <span class="token attr-value">DEPENDENCIES: 阶段的依赖关系</span>
<span class="token attr-name">  Stage-0</span> <span class="token attr-value">is a root stage</span>

<span class="token attr-name">STAGE</span> <span class="token attr-value">PLANS:</span>
<span class="token attr-name">  Stage</span><span class="token punctuation">:</span> <span class="token attr-value">Stage-0 </span>
<span class="token attr-name">    Fetch</span> <span class="token attr-value">Operator 抓取操作</span>
<span class="token attr-name">      limit</span><span class="token punctuation">:</span> <span class="token attr-value">-1 没有做任何的限制</span>
<span class="token attr-name">      Processor</span> <span class="token attr-value">Tree: 操作树</span>
<span class="token attr-name">        TableScan</span> <span class="token attr-value">扫描的表</span>
<span class="token attr-name">          alias</span><span class="token punctuation">:</span> <span class="token attr-value">bigtable</span>
<span class="token attr-name">          Select</span> <span class="token attr-value">Operator 操作列表</span>
<span class="token attr-name">            expressions</span><span class="token punctuation">:</span> <span class="token attr-value">id (type: bigint), t (type: bigint), uid (type: string), keyword (type: string), url_rank (type: int), click_num (type: int), click_url (type: string)</span>
<span class="token attr-name">            outputColumnNames</span><span class="token punctuation">:</span> <span class="token attr-value">_col0, _col1, _col2, _col3, _col4, _col5, _col6 输出的列名</span>
            ListSink

<span class="token attr-name">Time</span> <span class="token attr-value">taken: 0.167 seconds, Fetched: 15 row(s)</span>
</code></pre>
<pre class=" language-properties"><code class="language-properties"><span class="token attr-name">hive</span> <span class="token attr-value">(wmy)> explain select click_url, count(*) ct from bigtable group by click_url;</span>
OK
Explain
<span class="token attr-name">STAGE</span> <span class="token attr-value">DEPENDENCIES:</span>
<span class="token attr-name">  Stage-1</span> <span class="token attr-value">is a root stage 根阶段</span>
<span class="token attr-name">  Stage-0</span> <span class="token attr-value">depends on stages: Stage-1 依赖于第一阶段</span>

<span class="token attr-name">STAGE</span> <span class="token attr-value">PLANS:</span>
<span class="token attr-name">  Stage</span><span class="token punctuation">:</span> <span class="token attr-value">Stage-1 MR任务</span>
    Spark
<span class="token attr-name">      Edges</span><span class="token punctuation">:</span>
<span class="token attr-name">        Reducer</span> <span class="token attr-value">2 &lt;- Map 1 (GROUP, 11)</span>
<span class="token attr-name">      DagName</span><span class="token punctuation">:</span> <span class="token attr-value">root_20210824125146_d0b9a768-686b-48c3-8e62-cfdb35023df2:2</span>
<span class="token attr-name">      Vertices</span><span class="token punctuation">:</span>
<span class="token attr-name">        Map</span> <span class="token attr-value">1 </span>
<span class="token attr-name">            Map</span> <span class="token attr-value">Operator Tree:</span>
                TableScan
<span class="token attr-name">                  alias</span><span class="token punctuation">:</span> <span class="token attr-value">bigtable</span>
<span class="token attr-name">                  Statistics</span><span class="token punctuation">:</span> <span class="token attr-value">Num rows: 1 Data size: 1291573248 Basic stats: COMPLETE Column stats: NONE</span>
<span class="token attr-name">                  Select</span> <span class="token attr-value">Operator</span>
<span class="token attr-name">                    expressions</span><span class="token punctuation">:</span> <span class="token attr-value">click_url (type: string)</span>
<span class="token attr-name">                    outputColumnNames</span><span class="token punctuation">:</span> <span class="token attr-value">click_url</span>
<span class="token attr-name">                    Statistics</span><span class="token punctuation">:</span> <span class="token attr-value">Num rows: 1 Data size: 1291573248 Basic stats: COMPLETE Column stats: NONE 这个是内部直接给定的1</span>
<span class="token attr-name">                    Group</span> <span class="token attr-value">By Operator</span>
<span class="token attr-name">                      aggregations</span><span class="token punctuation">:</span> <span class="token attr-value">count()</span>
<span class="token attr-name">                      keys</span><span class="token punctuation">:</span> <span class="token attr-value">click_url (type: string)</span>
<span class="token attr-name">                      mode</span><span class="token punctuation">:</span> <span class="token attr-value">hash</span>
<span class="token attr-name">                      outputColumnNames</span><span class="token punctuation">:</span> <span class="token attr-value">_col0, _col1</span>
<span class="token attr-name">                      Statistics</span><span class="token punctuation">:</span> <span class="token attr-value">Num rows: 1 Data size: 1291573248 Basic stats: COMPLETE Column stats: NONE</span>
<span class="token attr-name">                      Reduce</span> <span class="token attr-value">Output Operator</span>
<span class="token attr-name">                        key</span> <span class="token attr-value">expressions: _col0 (type: string)</span>
<span class="token attr-name">                        sort</span> <span class="token attr-value">order: + 正序排序</span>
<span class="token attr-name">                        Map-reduce</span> <span class="token attr-value">partition columns: _col0 (type: string)</span>
<span class="token attr-name">                        Statistics</span><span class="token punctuation">:</span> <span class="token attr-value">Num rows: 1 Data size: 1291573248 Basic stats: COMPLETE Column stats: NONE</span>
<span class="token attr-name">                        value</span> <span class="token attr-value">expressions: _col1 (type: bigint)</span>
<span class="token attr-name">            Execution</span> <span class="token attr-value">mode: vectorized</span>
<span class="token attr-name">        Reducer</span> <span class="token attr-value">2 </span>
<span class="token attr-name">            Execution</span> <span class="token attr-value">mode: vectorized</span>
<span class="token attr-name">            Reduce</span> <span class="token attr-value">Operator Tree:</span>
<span class="token attr-name">              Group</span> <span class="token attr-value">By Operator</span>
<span class="token attr-name">                aggregations</span><span class="token punctuation">:</span> <span class="token attr-value">count(VALUE._col0) 做一个累加的结果</span>
<span class="token attr-name">                keys</span><span class="token punctuation">:</span> <span class="token attr-value">KEY._col0 (type: string)</span>
<span class="token attr-name">                mode</span><span class="token punctuation">:</span> <span class="token attr-value">mergepartial</span>
<span class="token attr-name">                outputColumnNames</span><span class="token punctuation">:</span> <span class="token attr-value">_col0, _col1</span>
<span class="token attr-name">                Statistics</span><span class="token punctuation">:</span> <span class="token attr-value">Num rows: 1 Data size: 1291573248 Basic stats: COMPLETE Column stats: NONE</span>
<span class="token attr-name">                File</span> <span class="token attr-value">Output Operator</span>
<span class="token attr-name">                  compressed</span><span class="token punctuation">:</span> <span class="token attr-value">false</span>
<span class="token attr-name">                  Statistics</span><span class="token punctuation">:</span> <span class="token attr-value">Num rows: 1 Data size: 1291573248 Basic stats: COMPLETE Column stats: NONE</span>
<span class="token attr-name">                  table</span><span class="token punctuation">:</span>
<span class="token attr-name">                      input</span> <span class="token attr-value">format: org.apache.hadoop.mapred.SequenceFileInputFormat</span>
<span class="token attr-name">                      output</span> <span class="token attr-value">format: org.apache.hadoop.hive.ql.io.HiveSequenceFileOutputFormat</span>
<span class="token attr-name">                      serde</span><span class="token punctuation">:</span> <span class="token attr-value">org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe</span>

<span class="token attr-name">  Stage</span><span class="token punctuation">:</span> <span class="token attr-value">Stage-0</span>
<span class="token attr-name">    Fetch</span> <span class="token attr-value">Operator</span>
<span class="token attr-name">      limit</span><span class="token punctuation">:</span> <span class="token attr-value">-1 将全部的结果给打印</span>
<span class="token attr-name">      Processor</span> <span class="token attr-value">Tree:</span>
        ListSink

<span class="token attr-name">Time</span> <span class="token attr-value">taken: 0.223 seconds, Fetched: 56 row(s)</span>
</code></pre>
<p>从简单的SQL了解起，写hive sql ，如果不用hive sql来进行实现，写MR程序如何实现，执行计划就是将hive sql翻译成MR的程序</p>
<p>是如何翻译成MR任务的</p>
<h4 id="2）查看详细执行计划"><a href="#2）查看详细执行计划" class="headerlink" title="2）查看详细执行计划"></a>2）查看详细执行计划</h4><pre class=" language-sql"><code class="language-sql"><span class="token keyword">explain</span> <span class="token keyword">extended</span> <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> bigtable<span class="token punctuation">;</span>
<span class="token keyword">explain</span> <span class="token keyword">extended</span> <span class="token keyword">select</span> click_url<span class="token punctuation">,</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> ct <span class="token keyword">from</span> bigtable <span class="token keyword">group</span> <span class="token keyword">by</span> click_url<span class="token punctuation">;</span>
</code></pre>
<p>一般的我们是不会去这样使用，多出的部分的数据我们并不是很关心的</p>
<h2 id="第-2-章-Hive-建表优化"><a href="#第-2-章-Hive-建表优化" class="headerlink" title="第 2 章 Hive 建表优化"></a>第 2 章 Hive 建表优化</h2><h3 id="2-1-分区表"><a href="#2-1-分区表" class="headerlink" title="2.1 分区表"></a>2.1 分区表</h3><p>分区表实际上就是对应一个 HDFS 文件系统上的独立的文件夹，该文件夹下是该分区所 有的数据文件。</p>
<p>Hive 中的分区就是分目录，把一个大的数据集根据业务需要分割成小的数据集。 </p>
<p>在查询时通过 WHERE 子句中的表达式选择查询所需要的指定的分区，这样的查询效率 会提高很多，所以我们需要把常常用在 WHERE 语句中的字段指定为表的分区字段。</p>
<h4 id="2-1-1-分区表基本操作"><a href="#2-1-1-分区表基本操作" class="headerlink" title="2.1.1 分区表基本操作"></a>2.1.1 分区表基本操作</h4><h5 id="1）引入分区表（需要根据日期对日志进行管理-通过部门信息模拟）"><a href="#1）引入分区表（需要根据日期对日志进行管理-通过部门信息模拟）" class="headerlink" title="1）引入分区表（需要根据日期对日志进行管理, 通过部门信息模拟）"></a>1）引入分区表（需要根据日期对日志进行管理, 通过部门信息模拟）</h5><pre class=" language-properties"><code class="language-properties">dept_20200401.log
dept_20200402.log
dept_20200403.log
</code></pre>
<h5 id="2）创建分区表语法"><a href="#2）创建分区表语法" class="headerlink" title="2）创建分区表语法"></a>2）创建分区表语法</h5><pre class=" language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> dept_partition
             <span class="token punctuation">(</span>
                          deptno <span class="token keyword">int</span>
                        <span class="token punctuation">,</span> dname string
                        <span class="token punctuation">,</span> loc string
             <span class="token punctuation">)</span>
             partitioned <span class="token keyword">by</span>
             <span class="token punctuation">(</span>
                          day string
             <span class="token punctuation">)</span>
             <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span>
<span class="token punctuation">;</span>
</code></pre>
<p>注意：分区字段不能是表中已经存在的数据，可以将分区字段看作表的伪列。</p>
<h5 id="3）加载数据到分区表中"><a href="#3）加载数据到分区表中" class="headerlink" title="3）加载数据到分区表中"></a>3）加载数据到分区表中</h5><h6 id="（1）数据准备"><a href="#（1）数据准备" class="headerlink" title="（1）数据准备"></a>（1）数据准备</h6><p>dept_20200401.log</p>
<pre class=" language-properties"><code class="language-properties"><span class="token attr-name">10</span> <span class="token attr-value">ACCOUNTING 1700</span>
<span class="token attr-name">20</span> <span class="token attr-value">RESEARCH 1800</span>
</code></pre>
<p>dept_20200402.log</p>
<pre class=" language-properties"><code class="language-properties"><span class="token attr-name">30</span> <span class="token attr-value">SALES 1900</span>
<span class="token attr-name">40</span> <span class="token attr-value">OPERATIONS 1700</span>
</code></pre>
<p>dept_20200403.log</p>
<pre class=" language-properties"><code class="language-properties"><span class="token attr-name">50</span> <span class="token attr-value">TEST 2000</span>
<span class="token attr-name">60</span> <span class="token attr-value">DEV 1900</span>
</code></pre>
<h6 id="（2）加载数据"><a href="#（2）加载数据" class="headerlink" title="（2）加载数据"></a>（2）加载数据</h6><pre class=" language-sql"><code class="language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/flink/hive/data/dept_20200401.log'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">partition</span><span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200401'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/flink/hive/data/dept_20200402.log'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">partition</span><span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200402'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/flink/hive/data/dept_20200403.log'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">partition</span><span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200403'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>注意：分区表加载数据时，必须指定分区</p>
<h5 id="4）查询分区表中数据"><a href="#4）查询分区表中数据" class="headerlink" title="4）查询分区表中数据"></a>4）查询分区表中数据</h5><pre class=" language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">-- 单分区查询</span>
<span class="token keyword">select</span> <span class="token operator">*</span>
<span class="token keyword">from</span>
       dept_partition
<span class="token keyword">where</span>
       day<span class="token operator">=</span><span class="token string">'20200401'</span>
<span class="token punctuation">;</span>

<span class="token comment" spellcheck="true">-- 多分区查询</span>
<span class="token keyword">select</span> <span class="token operator">*</span>
<span class="token keyword">from</span>
       dept_partition
<span class="token keyword">where</span>
       day<span class="token operator">=</span><span class="token string">'20200401'</span>
<span class="token keyword">union</span>
<span class="token keyword">select</span> <span class="token operator">*</span>
<span class="token keyword">from</span>
       dept_partition
<span class="token keyword">where</span>
       day<span class="token operator">=</span><span class="token string">'20200402'</span>
<span class="token keyword">union</span>
<span class="token keyword">select</span> <span class="token operator">*</span>
<span class="token keyword">from</span>
       dept_partition
<span class="token keyword">where</span>
       day<span class="token operator">=</span><span class="token string">'20200403'</span>
<span class="token punctuation">;</span>
</code></pre>
<p><img src="https://gitee.com/wmybigdata/blog-drawing-bed/raw/master/img/image-20210824131047329.png" alt="分区中的数据"></p>
<h5 id="5）增加分区"><a href="#5）增加分区" class="headerlink" title="5）增加分区"></a>5）增加分区</h5><pre class=" language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">-- 增加单个分区</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">add</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200404'</span><span class="token punctuation">)</span>
<span class="token punctuation">;</span>

<span class="token comment" spellcheck="true">-- 增加多个分区</span>
 <span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">add</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200405'</span><span class="token punctuation">)</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200406'</span><span class="token punctuation">)</span>
 <span class="token punctuation">;</span>
</code></pre>
<h5 id="6）删除分区"><a href="#6）删除分区" class="headerlink" title="6）删除分区"></a>6）删除分区</h5><pre class=" language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">-- 删除单个分区</span>
<span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">drop</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200406'</span><span class="token punctuation">)</span>
<span class="token punctuation">;</span>

<span class="token comment" spellcheck="true">-- 删除多个分区</span>
 <span class="token keyword">alter</span> <span class="token keyword">table</span> dept_partition <span class="token keyword">drop</span> <span class="token keyword">partition</span> <span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200404'</span><span class="token punctuation">)</span>
           <span class="token punctuation">,</span> <span class="token keyword">partition</span><span class="token punctuation">(</span>day                     <span class="token operator">=</span><span class="token string">'20200405'</span><span class="token punctuation">)</span>
 <span class="token punctuation">;</span>
</code></pre>
<h5 id="7）查看分区表有多少分区"><a href="#7）查看分区表有多少分区" class="headerlink" title="7）查看分区表有多少分区"></a>7）查看分区表有多少分区</h5><pre class=" language-sql"><code class="language-sql"><span class="token keyword">show</span> partitions dept_partition<span class="token punctuation">;</span>
</code></pre>
<h5 id="8）查看分区表结构"><a href="#8）查看分区表结构" class="headerlink" title="8）查看分区表结构"></a>8）查看分区表结构</h5><pre class=" language-sql"><code class="language-sql"> <span class="token keyword">desc</span> formatted dept_partition<span class="token punctuation">;</span>
</code></pre>
<p>思考: 如果一天的日志数据量也很大，如何再将数据拆分?</p>
<h4 id="2-1-2-二级分区"><a href="#2-1-2-二级分区" class="headerlink" title="2.1.2 二级分区"></a>2.1.2 二级分区</h4><h5 id="1）创建二级分区表"><a href="#1）创建二级分区表" class="headerlink" title="1）创建二级分区表"></a>1）创建二级分区表</h5><pre class=" language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> dept_partition2
             <span class="token punctuation">(</span>
                          deptno <span class="token keyword">int</span>
                        <span class="token punctuation">,</span> dname string
                        <span class="token punctuation">,</span> loc string
             <span class="token punctuation">)</span>
             partitioned <span class="token keyword">by</span>
             <span class="token punctuation">(</span>
                          day string
                        <span class="token punctuation">,</span> hour string
             <span class="token punctuation">)</span>
             <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span>
<span class="token punctuation">;</span>
</code></pre>
<h5 id="2）正常的加载数据"><a href="#2）正常的加载数据" class="headerlink" title="2）正常的加载数据"></a>2）正常的加载数据</h5><h5 id="（1）加载数据到二级分区表中"><a href="#（1）加载数据到二级分区表中" class="headerlink" title="（1）加载数据到二级分区表中"></a>（1）加载数据到二级分区表中</h5><pre class=" language-sql"><code class="language-sql"><span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/flink/hive/data/dept_20200401.log'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> dept_partition2 <span class="token keyword">partition</span><span class="token punctuation">(</span>day<span class="token operator">=</span><span class="token string">'20200401'</span><span class="token punctuation">,</span> hour<span class="token operator">=</span><span class="token string">'12'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<h5 id="（2）查询分区数据"><a href="#（2）查询分区数据" class="headerlink" title="（2）查询分区数据"></a>（2）查询分区数据</h5><pre class=" language-sql"><code class="language-sql"> <span class="token keyword">select</span> <span class="token operator">*</span>
 <span class="token keyword">from</span>
        dept_partition2
 <span class="token keyword">where</span>
        day     <span class="token operator">=</span><span class="token string">'20200401'</span>
        <span class="token operator">and</span> hour<span class="token operator">=</span><span class="token string">'12'</span>
 <span class="token punctuation">;</span>
</code></pre>
<h4 id="2-1-3-动态分区"><a href="#2-1-3-动态分区" class="headerlink" title="2.1.3 动态分区"></a>2.1.3 动态分区</h4><p>关系型数据库中，对分区表 Insert 数据时候，数据库自动会根据分区字段的值，将数据 插入到相应的分区中，Hive 中也提供了类似的机制，即动态分区(Dynamic Partition)，只不过， 使用 Hive 的动态分区，需要进行相应的配置。</p>
<h5 id="1）开启动态分区参数设置"><a href="#1）开启动态分区参数设置" class="headerlink" title="1）开启动态分区参数设置"></a>1）开启动态分区参数设置</h5><p>（1）开启动态分区功能（默认 true，开启）</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre>
<p>（2）设置为非严格模式（动态分区的模式，默认 strict，表示必须指定至少一个分区为 静态分区，nonstrict 模式表示允许所有的分区字段都可以使用动态分区。）</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span>mode<span class="token operator">=</span>nonstrict<span class="token punctuation">;</span>
</code></pre>
<p>（3）在所有执行 MR 的节点上，最大一共可以创建多少个动态分区。默认 1000</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>max<span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span>partitions<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">;</span>
</code></pre>
<p>（4）在每个执行 MR 的节点上，最大可以创建多少个动态分区。</p>
<p>该参数需要根据实际的数据来设定。比如：源数据中包含了一年的数据，即 day 字段有 365 个值，那么该参数就需要设置成大于 365，如果使用默认值 100，则会报错。</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>max<span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span>partitions<span class="token punctuation">.</span>pernode<span class="token operator">=</span><span class="token number">100</span>
</code></pre>
<p>（5）整个 MR Job 中，最大可以创建多少个 HDFS 文件。默认 100000</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>max<span class="token punctuation">.</span>created<span class="token punctuation">.</span>files<span class="token operator">=</span><span class="token number">100000</span>
</code></pre>
<p>（6）当有空分区生成时，是否抛出异常。一般不需要设置。默认 false</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>error<span class="token punctuation">.</span><span class="token keyword">on</span><span class="token punctuation">.</span>empty<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token operator">=</span><span class="token boolean">false</span>
</code></pre>
<h5 id="2）案例实操"><a href="#2）案例实操" class="headerlink" title="2）案例实操"></a>2）案例实操</h5><p>需求：将 dept 表中的数据按照地区（loc 字段），插入到目标表 dept_partition 的相应分 区中。</p>
<p>（1）创建目标分区表</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> dept_partition_dy
             <span class="token punctuation">(</span>
                          id <span class="token keyword">int</span>
                        <span class="token punctuation">,</span> name string
             <span class="token punctuation">)</span>
             partitioned <span class="token keyword">by</span>
             <span class="token punctuation">(</span>
                          loc string
             <span class="token punctuation">)</span>
             <span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span>
<span class="token punctuation">;</span>
</code></pre>
<p>（2）设置动态分区</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>dynamic<span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span>mode <span class="token operator">=</span> nonstrict<span class="token punctuation">;</span>
<span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> dept_partition_dy <span class="token keyword">partition</span>
       <span class="token punctuation">(</span>loc
       <span class="token punctuation">)</span>
<span class="token keyword">select</span>
       deptno
     <span class="token punctuation">,</span> dname
     <span class="token punctuation">,</span> loc
<span class="token keyword">from</span>
       dept
<span class="token punctuation">;</span>
</code></pre>
<p>（3）查看目标分区表的分区情况</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">show</span> partitions dept_partition<span class="token punctuation">;</span>
</code></pre>
<p>记住，使用分区表，分区表的里面的字段和查询出来的字段的类型是必须要一致的，否则的话会出现问题的</p>
<h3 id="2-2-分桶表"><a href="#2-2-分桶表" class="headerlink" title="2.2 分桶表"></a>2.2 分桶表</h3><p>分区提供一个隔离数据和优化查询的便利方式。不过，并非所有的数据集都可形成合理 的分区。对于一张表或者分区，Hive 可以进一步组织成桶，也就是更为细粒度的数据范围 划分。 </p>
<p>分桶是将数据集分解成更容易管理的若干部分的另一个技术。分区针对的是数据的存储 路径，分桶针对的是数据文件。</p>
<h4 id="2-2-1-创建分桶表"><a href="#2-2-1-创建分桶表" class="headerlink" title="2.2.1 创建分桶表"></a>2.2.1 创建分桶表</h4><p>（1）数据准备</p>
<pre class=" language-properties"><code class="language-properties">1001,ss1
1002,ss2
1003,ss3
1004,ss4
1005,ss5
1006,ss6
1007,ss7
1008,ss8
1009,ss9
1010,ss10
1011,ss11
1012,ss12
1013,ss13
1014,ss14
1015,ss15
1016,ss16
</code></pre>
<p>（2）创建分桶表</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> stu_buck<span class="token punctuation">(</span>id <span class="token keyword">int</span><span class="token punctuation">,</span> name string<span class="token punctuation">)</span>
<span class="token keyword">clustered</span> <span class="token keyword">by</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span>
<span class="token keyword">into</span> <span class="token number">4</span> buckets
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">','</span><span class="token punctuation">;</span>
</code></pre>
<p>（3）查看表结构</p>
<pre class=" language-sql"><code class="language-sql"> <span class="token keyword">desc</span> formatted stu_buck<span class="token punctuation">;</span>
</code></pre>
<p>（4）导入数据到分桶表中，load 的方式</p>
<pre class=" language-sql"><code class="language-sql"> <span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/flink/hive/data/student.txt'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> stu_buck<span class="token punctuation">;</span>
</code></pre>
<p>（5）查看创建的分桶表中是否分成 4 个桶</p>
<p><img src="https://gitee.com/wmybigdata/blog-drawing-bed/raw/master/img/image-20210824141808132.png" alt="image-20210824141808132"></p>
<p>（6）查询分桶的数据</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> stu_buck<span class="token punctuation">;</span>
</code></pre>
<p>（7）分桶规则：</p>
<p>根据结果可知：Hive 的分桶采用对分桶字段的值进行哈希，然后除以桶的个数求余的方 式决定该条记录存放在哪个桶当中</p>
<p>2）分桶表操作需要注意的事项</p>
<p>（1）reduce 的个数设置为-1，让 Job 自行决定需要用多少个 reduce 或者将 reduce 的个 数设置为大于等于分桶表的桶数 </p>
<p>（2）从 hdfs 中 load 数据到分桶表中，避免本地文件找不到问题 </p>
<p>（3）不要使用本地模式</p>
<p>3）insert 方式将数据导入分桶表</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">insert</span> <span class="token keyword">into</span> <span class="token keyword">table</span> stu_buck <span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> student_insert<span class="token punctuation">;</span>
</code></pre>
<h4 id="2-2-2-抽样查询"><a href="#2-2-2-抽样查询" class="headerlink" title="2.2.2 抽样查询"></a>2.2.2 抽样查询</h4><p>对于非常大的数据集，有时用户需要使用的是一个具有代表性的查询结果而不是全部结 果。</p>
<p>Hive 可以通过对表进行抽样来满足这个需求。 </p>
<p>语法: TABLESAMPLE(BUCKET x OUT OF y) 查询表 stu_buck 中的数据。</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> stu_buck tablesample<span class="token punctuation">(</span>bucket <span class="token number">1</span> <span class="token keyword">out</span> <span class="token keyword">of</span> <span class="token number">4</span> <span class="token keyword">on</span> id<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>注意：x 的值必须小于等于 y 的值，否则</p>
<pre class=" language-properties"><code class="language-properties"><span class="token attr-name">FAILED</span><span class="token punctuation">:</span> <span class="token attr-value">SemanticException [Error 10061]: Numerator should not be bigger</span>
<span class="token attr-name">than</span> <span class="token attr-value">denominator in sample clause for table stu_buck</span>
</code></pre>
<h3 id="2-3-合适的文件格式"><a href="#2-3-合适的文件格式" class="headerlink" title="2.3 合适的文件格式"></a>2.3 合适的文件格式</h3><p>Hive 支持的存储数据的格式主要有：TEXTFILE 、SEQUENCEFILE、ORC、PARQUET。</p>
<h4 id="2-3-1-列式存储和行式存储"><a href="#2-3-1-列式存储和行式存储" class="headerlink" title="2.3.1 列式存储和行式存储"></a>2.3.1 列式存储和行式存储</h4><p>1）行存储的特点</p>
<p>​    查询满足条件的一整行数据的时候，列存储则需要去每个聚集的字段找到对应的每个列 的值，行存储只需要找到其中一个值，其余的值都在相邻地方，所以此时行存储查询的速度 更快。</p>
<p>​    TEXTFILE 和 SEQUENCEFILE 的存储格式都是基于行存储的；</p>
<p>2）列存储的特点</p>
<p>​    因为每个字段的数据聚集存储，在查询只需要少数几个字段的时候，能大大减少读取的 数据量；每个字段的数据类型一定是相同的，列式存储可以针对性的设计更好的设计压缩算 法。</p>
<p>​    ORC 和 PARQUET 是基于列式存储的。</p>
<h4 id="2-3-2-TextFile格式"><a href="#2-3-2-TextFile格式" class="headerlink" title="2.3.2 TextFile格式"></a>2.3.2 TextFile格式</h4><p>​    默认格式，数据不做压缩，磁盘开销大，数据解析开销大。可结合 Gzip、Bzip2 使用， 但使用 Gzip 这种方式，hive 不会对数据进行切分，从而无法对数据进行并行操作。</p>
<h4 id="2-3-3-Orc格式"><a href="#2-3-3-Orc格式" class="headerlink" title="2.3.3 Orc格式"></a>2.3.3 Orc格式</h4><p>​    Orc (Optimized Row Columnar)是 Hive 0.11 版里引入的新的存储格式。</p>
<h4 id="2-3-4-Parquet格式"><a href="#2-3-4-Parquet格式" class="headerlink" title="2.3.4 Parquet格式"></a>2.3.4 Parquet格式</h4><p>​    Parquet 文件是以二进制方式存储的，所以是不可以直接读取的，文件中包括该文件的 数据和元数据，因此 Parquet 格式文件是自解析的。</p>
<h3 id="2-4-合适的压缩格式"><a href="#2-4-合适的压缩格式" class="headerlink" title="2.4 合适的压缩格式"></a>2.4 合适的压缩格式</h3><p><img src="https://gitee.com/wmybigdata/blog-drawing-bed/raw/master/img/image-20210825131543316.png" alt="压缩数据格式"></p>
<p>为了支持多种压缩/解压缩算法，Hadoop 引入了编码/解码器，如下表所示。</p>
<p><img src="https://gitee.com/wmybigdata/blog-drawing-bed/raw/master/img/image-20210825131735589.png" alt="编码和解码器"></p>
<p>压缩性能的比较</p>
<p><a href="http://google.github.io/snappy/" target="_blank" rel="noopener">Snappy压缩算法</a></p>
<p>在64位模式的酷睿i7处理器的单核上，Snappy压缩速度约为250mb /秒，解压缩速度约为500mb /秒。  </p>
<h2 id="第-3-章-HQL-语法优化"><a href="#第-3-章-HQL-语法优化" class="headerlink" title="第 3 章 HQL 语法优化"></a>第 3 章 HQL 语法优化</h2><h3 id="3-1-列裁剪与分区裁剪"><a href="#3-1-列裁剪与分区裁剪" class="headerlink" title="3.1 列裁剪与分区裁剪"></a>3.1 列裁剪与分区裁剪</h3><p>​    列裁剪就是在查询时只读取需要的列，分区裁剪就是只读取需要的分区。当列很多或者 数据量很大时，如果 select * 或者不指定分区，全列扫描和全表扫描效率都很低。 Hive 在读数据的时候，可以只读取查询中所需要用到的列，而忽略其他的列。这样做 可以节省读取开销：中间表存储开销和数据整合开销。</p>
<h3 id="3-2-Group-By"><a href="#3-2-Group-By" class="headerlink" title="3.2 Group By"></a>3.2 Group By</h3><p>​    默认情况下，Map 阶段同一 Key 数据分发给一个 Reduce，当一个 key 数据过大时就倾 斜了。</p>
<p><img src="https://gitee.com/wmybigdata/blog-drawing-bed/raw/master/img/image-20210825132110865.png" alt="数据倾斜"></p>
<p>并不是所有的聚合操作都需要在 Reduce 端完成，很多聚合操作都可以先在 Map 端进行 部分聚合，最后在 Reduce 端得出最终结果。</p>
<h4 id="3-2-1-开启-Map-端聚合参数设置"><a href="#3-2-1-开启-Map-端聚合参数设置" class="headerlink" title="3.2.1 开启 Map 端聚合参数设置"></a>3.2.1 开启 Map 端聚合参数设置</h4><p>（1）是否在 Map 端进行聚合，默认为 True</p>
<pre class=" language-properties"><code class="language-properties"><span class="token attr-name">set</span> <span class="token attr-value">hive.map.aggr = true;</span>
</code></pre>
<p>（2）在 Map 端进行聚合操作的条目数目</p>
<pre class=" language-properties"><code class="language-properties"><span class="token attr-name">set</span> <span class="token attr-value">hive.groupby.mapaggr.checkinterval = 100000;</span>
</code></pre>
<p>（3）有数据倾斜的时候进行负载均衡（默认是 false）</p>
<pre class=" language-properties"><code class="language-properties"><span class="token attr-name">set</span> <span class="token attr-value">hive.groupby.skewindata = true;</span>
</code></pre>
<p>​    当选项设定为 true，生成的查询计划会有两个 MR Job。</p>
<p>​    第一个 MR Job 中，Map 的输出结果会随机分布到 Reduce 中，每个 Reduce 做部分聚合 操作，并输出结果，这样处理的结果是相同的 Group By Key 有可能被分发到不同的 Reduce 中，从而达到负载均衡的目的；</p>
<p>​    第二个 MR Job 再根据预处理的数据结果按照 Group By Key 分布到 Reduce 中（这个过程可以保证相同的 Group By Key 被分布到同一个 Reduce 中），最后完成最终的聚合操作（虽然 能解决数据倾斜，但是不能让运行速度的更快）。</p>
<h3 id="3-3-Vectorization"><a href="#3-3-Vectorization" class="headerlink" title="3.3 Vectorization"></a>3.3 Vectorization</h3><p>​    vectorization : 矢量计算的技术，在计算类似scan, filter, aggregation的时候，vectorization 技术以设置批处理的增量大小为 1024 行单次来达到比单条记录单次获得更高的效率。</p>
<p><img src="https://gitee.com/wmybigdata/blog-drawing-bed/raw/master/img/image-20210825133949490.png" alt="矢量查询"></p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>vectorized<span class="token punctuation">.</span>execution<span class="token punctuation">.</span>enabled <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>vectorized<span class="token punctuation">.</span>execution<span class="token punctuation">.</span>reduce<span class="token punctuation">.</span>enabled <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre>
<h3 id="3-4-多重模式"><a href="#3-4-多重模式" class="headerlink" title="3.4 多重模式"></a>3.4 多重模式</h3><p>​    如果你碰到一堆 SQL，并且这一堆 SQL 的模式还一样。都是从同一个表进行扫描，做不 同的逻辑。有可优化的地方：如果有 n 条 SQL，每个 SQL 执行都会扫描一次这张表。</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">from</span> student
<span class="token keyword">insert</span> <span class="token keyword">int</span> t_ptn <span class="token keyword">partition</span><span class="token punctuation">(</span>city<span class="token operator">=</span>A<span class="token punctuation">)</span> <span class="token keyword">select</span> id<span class="token punctuation">,</span>name<span class="token punctuation">,</span>sex<span class="token punctuation">,</span> age <span class="token keyword">where</span> city<span class="token operator">=</span> A
<span class="token keyword">insert</span> <span class="token keyword">int</span> t_ptn <span class="token keyword">partition</span><span class="token punctuation">(</span>city<span class="token operator">=</span>B<span class="token punctuation">)</span> <span class="token keyword">select</span> id<span class="token punctuation">,</span>name<span class="token punctuation">,</span>sex<span class="token punctuation">,</span> age <span class="token keyword">where</span> city<span class="token operator">=</span> B
</code></pre>
<p>​    如果一个 HQL 底层要执行 10 个 Job，那么能优化成 8 个一般来说，肯定能有所提高， 多重插入就是一个非常实用的技能。一次读取，多次插入，有些场景是从一张表读取数据后， 要多次利用。</p>
<h3 id="3-5-in-exists-语句"><a href="#3-5-in-exists-语句" class="headerlink" title="3.5 in/exists 语句"></a>3.5 in/exists 语句</h3><p>​    在 Hive 的早期版本中，in/exists 语法是不被支持的，但是从 hive-0.8x 以后就开始支持 这个语法。但是不推荐使用这个语法。虽然经过测验，Hive-2.3.6 也支持 in/exists 操作，但 还是推荐使用 Hive 的一个高效替代方案：left semi join</p>
<p>​    比如说：– in / exists 实现    </p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token number">a</span><span class="token punctuation">.</span>id<span class="token punctuation">,</span> <span class="token number">a</span><span class="token punctuation">.</span>name <span class="token keyword">from</span> <span class="token number">a</span> <span class="token keyword">where</span> <span class="token number">a</span><span class="token punctuation">.</span>id <span class="token operator">in</span> <span class="token punctuation">(</span><span class="token keyword">select</span> <span class="token number">b</span><span class="token punctuation">.</span>id <span class="token keyword">from</span> <span class="token number">b</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token number">a</span><span class="token punctuation">.</span>id<span class="token punctuation">,</span> <span class="token number">a</span><span class="token punctuation">.</span>name <span class="token keyword">from</span> <span class="token number">a</span> <span class="token keyword">where</span> <span class="token keyword">exists</span> <span class="token punctuation">(</span><span class="token keyword">select</span> id <span class="token keyword">from</span> <span class="token number">b</span> <span class="token keyword">where</span> <span class="token number">a</span><span class="token punctuation">.</span>id <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>id<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p>可以使用 join 来改写：</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token number">a</span><span class="token punctuation">.</span>id<span class="token punctuation">,</span> <span class="token number">a</span><span class="token punctuation">.</span>name <span class="token keyword">from</span> <span class="token number">a</span> <span class="token keyword">join</span> <span class="token number">b</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>id <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre>
<p>应该转换成： – left semi join 实现</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token number">a</span><span class="token punctuation">.</span>id<span class="token punctuation">,</span> <span class="token number">a</span><span class="token punctuation">.</span>name <span class="token keyword">from</span> <span class="token number">a</span> <span class="token keyword">left</span> semi <span class="token keyword">join</span> <span class="token number">b</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>id <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre>
<h3 id="3-6-CBO-优化"><a href="#3-6-CBO-优化" class="headerlink" title="3.6 CBO 优化"></a>3.6 CBO 优化</h3><p>join 的时候表的顺序的关系：前面的表都会被加载到内存中。后面的表进行磁盘扫描</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token number">a</span><span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span><span class="token operator">*</span><span class="token punctuation">,</span> <span class="token number">c</span><span class="token punctuation">.</span><span class="token operator">*</span> <span class="token keyword">from</span> <span class="token number">a</span> <span class="token keyword">join</span> <span class="token number">b</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>id <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>id <span class="token keyword">join</span> <span class="token number">c</span> <span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>id <span class="token operator">=</span> <span class="token number">c</span><span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre>
<p>​    Hive 自 0.14.0 开始，加入了一项 “Cost based Optimizer” 来对 HQL 执行计划进行优化， 这个功能通过 “hive.cbo.enable” 来开启。    在 Hive 1.1.0 之后，这个 feature 是默认开启的， 它可以 自动优化 HQL 中多个 Join 的顺序，并选择合适的 Join 算法。 CBO，成本优化器，代价最小的执行计划就是最好的执行计划。传统的数据库，成本优 化器做出最优化的执行计划是依据统计信息来计算的。 Hive 的成本优化器也一样，Hive 在提供最终执行前，优化每个查询的执行逻辑和物理 执行计划。这些优化工作是交给底层来完成的。根据查询成本执行进一步的优化，从而产生 潜在的不同决策：如何排序连接，执行哪种类型的连接，并行度等等。</p>
<p>​    要使用基于成本的优化（也称为 CBO），请在查询开始设置以下参数：</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>cbo<span class="token punctuation">.</span><span class="token keyword">enable</span><span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">compute</span><span class="token punctuation">.</span>query<span class="token punctuation">.</span><span class="token keyword">using</span><span class="token punctuation">.</span>stats<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>stats<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span><span class="token keyword">column</span><span class="token punctuation">.</span>stats<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>stats<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span><span class="token keyword">partition</span><span class="token punctuation">.</span>stats<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre>
<h3 id="3-7-谓词下推"><a href="#3-7-谓词下推" class="headerlink" title="3.7 谓词下推"></a>3.7 谓词下推</h3><p>​    将 SQL 语句中的 where 谓词逻辑都尽可能提前执行，减少下游处理的数据量。对应逻 辑优化器是 PredicatePushDown，配置项为 hive.optimize.ppd，默认为 true。 案例实操：</p>
<p>1）打开谓词下推优化属性</p>
<pre class=" language-sql"><code class="language-sql"> <span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">optimize</span><span class="token punctuation">.</span>ppd <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">-- 谓词下推，默认是 true</span>
</code></pre>
<p>2）查看先关联两张表，再用 where 条件过滤的执行计划</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">explain</span> <span class="token keyword">select</span> o<span class="token punctuation">.</span>id <span class="token keyword">from</span> bigtable <span class="token number">b</span> <span class="token keyword">join</span> bigtable o <span class="token keyword">on</span> o<span class="token punctuation">.</span>id <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>id <span class="token keyword">where</span> o<span class="token punctuation">.</span>id <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">;</span>
</code></pre>
<p>3）查看子查询后，再关联表的执行计划</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">explain</span> <span class="token keyword">select</span> <span class="token number">b</span><span class="token punctuation">.</span>id <span class="token keyword">from</span> bigtable <span class="token number">b</span> <span class="token keyword">join</span> <span class="token punctuation">(</span><span class="token keyword">select</span> id <span class="token keyword">from</span> bigtable <span class="token keyword">where</span> id <span class="token operator">&lt;=</span> <span class="token number">10</span><span class="token punctuation">)</span> o <span class="token keyword">on</span> <span class="token number">b</span><span class="token punctuation">.</span>id <span class="token operator">=</span> o<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre>
<h3 id="3-8-MapJoin"><a href="#3-8-MapJoin" class="headerlink" title="3.8 MapJoin"></a>3.8 MapJoin</h3><p>​    MapJoin 是将 Join 双方比较小的表直接分发到各个 Map 进程的内存中，在 Map 进程中进行 Join 操 作，这样就不用进行 Reduce 步骤，从而提高了速度。如果不指定 MapJoin 或者不符合 MapJoin 的条件，那么 Hive 解析器会将 Join 操作转换成 Common Join，即：在 Reduce 阶段完成 Join。容易发生数据倾斜。可以用 MapJoin 把小表全部加载到内存在 Map 端进行 Join，避免 Reducer 处理。</p>
<p>1）开启 MapJoin 参数设置</p>
<p>（1）设置自动选择 MapJoin</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>auto<span class="token punctuation">.</span><span class="token keyword">convert</span><span class="token punctuation">.</span><span class="token keyword">join</span><span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">-- 默认为 true</span>
</code></pre>
<p>（2）大表小表的阈值设置（默认 25M 以下认为是小表）：</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>mapjoin<span class="token punctuation">.</span>smalltable<span class="token punctuation">.</span>filesize<span class="token operator">=</span><span class="token number">25000000</span><span class="token punctuation">;</span>
</code></pre>
<p>2）MapJoin 工作机制</p>
<p>​    MapJoin 是将 Join 双方比较小的表直接分发到各个 Map 进程的内存中，在 Map 进 程中进行 Join 操作，这样就不用进行 Reduce 步骤，从而提高了速度。</p>
<p>3）案例实操</p>
<p>（1）开启 MapJoin 功能</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>auto<span class="token punctuation">.</span><span class="token keyword">convert</span><span class="token punctuation">.</span><span class="token keyword">join</span> <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">-- 默认为 true</span>
</code></pre>
<p>（2）执行小表 JOIN 大表语句</p>
<p>注意：此时小表(左连接)作为主表，所有数据都要写出去，因此此时会走 reduce，mapjoin 失效</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">explain</span> <span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> jointable
<span class="token keyword">select</span> <span class="token number">b</span><span class="token punctuation">.</span>id<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>t<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>uid<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>keyword<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>url_rank<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>click_num<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>click_url
<span class="token keyword">from</span> smalltable s
<span class="token keyword">left</span> <span class="token keyword">join</span> bigtable <span class="token number">b</span>
<span class="token keyword">on</span> s<span class="token punctuation">.</span>id <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre>
<p>（3）执行大表 JOIN 小表语句</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">Explain</span> <span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> jointable
<span class="token keyword">select</span> <span class="token number">b</span><span class="token punctuation">.</span>id<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>t<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>uid<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>keyword<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>url_rank<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>click_num<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>click_url
<span class="token keyword">from</span> bigtable <span class="token number">b</span>
<span class="token keyword">left</span> <span class="token keyword">join</span> smalltable s
<span class="token keyword">on</span> s<span class="token punctuation">.</span>id <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre>
<h3 id="3-9-大表、大表-SMB-Join（重点）"><a href="#3-9-大表、大表-SMB-Join（重点）" class="headerlink" title="3.9 大表、大表 SMB Join（重点）"></a>3.9 大表、大表 SMB Join（重点）</h3><p>SMB Join ：Sort Merge Bucket Join</p>
<p>1）创建第二张大表</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> bigtable2<span class="token punctuation">(</span>
 id <span class="token keyword">bigint</span><span class="token punctuation">,</span>
 t <span class="token keyword">bigint</span><span class="token punctuation">,</span>
 uid string<span class="token punctuation">,</span>
 keyword string<span class="token punctuation">,</span>
 url_rank <span class="token keyword">int</span><span class="token punctuation">,</span>
 click_num <span class="token keyword">int</span><span class="token punctuation">,</span>
 click_url string<span class="token punctuation">)</span>
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/flink/hive/data/bigtable'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> bigtable2<span class="token punctuation">;</span>
</code></pre>
<p>2）测试大表直接 JOIN</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> jointable
<span class="token keyword">select</span> <span class="token number">b</span><span class="token punctuation">.</span>id<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>t<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>uid<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>keyword<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>url_rank<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>click_num<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>click_url
<span class="token keyword">from</span> bigtable <span class="token number">a</span>
<span class="token keyword">join</span> bigtable2 <span class="token number">b</span>
<span class="token keyword">on</span> <span class="token number">a</span><span class="token punctuation">.</span>id <span class="token operator">=</span> <span class="token number">b</span><span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre>
<p>3）创建分通表 1</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> bigtable_buck1<span class="token punctuation">(</span>
 id <span class="token keyword">bigint</span><span class="token punctuation">,</span>
 t <span class="token keyword">bigint</span><span class="token punctuation">,</span>
 uid string<span class="token punctuation">,</span>
 keyword string<span class="token punctuation">,</span>
 url_rank <span class="token keyword">int</span><span class="token punctuation">,</span>
 click_num <span class="token keyword">int</span><span class="token punctuation">,</span>
 click_url string<span class="token punctuation">)</span>
<span class="token keyword">clustered</span> <span class="token keyword">by</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span>
sorted <span class="token keyword">by</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span>
<span class="token keyword">into</span> <span class="token number">6</span> buckets
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/flink/hive/data/bigtable'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> bigtable_buck1<span class="token punctuation">;</span>
</code></pre>
<p>4）创建分通表 2，分桶数和第一张表的分桶数为倍数关系</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">create</span> <span class="token keyword">table</span> bigtable_buck2<span class="token punctuation">(</span>
 id <span class="token keyword">bigint</span><span class="token punctuation">,</span>
 t <span class="token keyword">bigint</span><span class="token punctuation">,</span>
 uid string<span class="token punctuation">,</span>
 keyword string<span class="token punctuation">,</span>
 url_rank <span class="token keyword">int</span><span class="token punctuation">,</span>
 click_num <span class="token keyword">int</span><span class="token punctuation">,</span>
 click_url string<span class="token punctuation">)</span>
<span class="token keyword">clustered</span> <span class="token keyword">by</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span>
sorted <span class="token keyword">by</span><span class="token punctuation">(</span>id<span class="token punctuation">)</span>
<span class="token keyword">into</span> <span class="token number">6</span> buckets
<span class="token keyword">row</span> format delimited <span class="token keyword">fields</span> <span class="token keyword">terminated by</span> <span class="token string">'\t'</span><span class="token punctuation">;</span>
<span class="token keyword">load</span> <span class="token keyword">data</span> <span class="token keyword">local</span> inpath <span class="token string">'/opt/flink/hive/data/bigtable'</span> <span class="token keyword">into</span> <span class="token keyword">table</span> bigtable_buck2<span class="token punctuation">;</span>
</code></pre>
<p>5）设置参数</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">optimize</span><span class="token punctuation">.</span>bucketmapjoin <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">optimize</span><span class="token punctuation">.</span>bucketmapjoin<span class="token punctuation">.</span>sortedmerge <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>input<span class="token punctuation">.</span>format<span class="token operator">=</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>io<span class="token punctuation">.</span>BucketizedHiveInputFormat<span class="token punctuation">;</span>
</code></pre>
<p>6）测试 Time taken: 34.685 seconds</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">insert</span> overwrite <span class="token keyword">table</span> jointable
<span class="token keyword">select</span> <span class="token number">b</span><span class="token punctuation">.</span>id<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>t<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>uid<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>keyword<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>url_rank<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>click_num<span class="token punctuation">,</span> <span class="token number">b</span><span class="token punctuation">.</span>click_url
<span class="token keyword">from</span> bigtable_buck1 s
<span class="token keyword">join</span> bigtable_buck2 <span class="token number">b</span>
<span class="token keyword">on</span> <span class="token number">b</span><span class="token punctuation">.</span>id <span class="token operator">=</span> s<span class="token punctuation">.</span>id<span class="token punctuation">;</span>
</code></pre>
<p>3.10 笛卡尔积</p>
<p>​    Join 的时候不加 on 条件，或者无效的 on 条件，因为找不到 Join key，Hive 只能使用 1 个 Reducer 来完成笛卡尔积。当 Hive 设定为严格模式（hive.mapred.mode=strict，nonstrict） 时，不允许在 HQL 语句中出现笛卡尔积。</p>
<h2 id="第-4-章-数据倾斜（重点）"><a href="#第-4-章-数据倾斜（重点）" class="headerlink" title="第 4 章 数据倾斜（重点）"></a>第 4 章 数据倾斜（重点）</h2><p>​    绝大部分任务都很快完成，只有一个或者少数几个任务执行的很慢甚至最终执行失败， 这样的现象为数据倾斜现象。 </p>
<p>​    一定要和数据过量导致的现象区分开，数据过量的表现为所有任务都执行的很慢，这个 时候只有提高执行资源才可以优化 HQL 的执行效率。 </p>
<p>​    综合来看，导致数据倾斜的原因在于按照 Key 分组以后，少量的任务负责绝大部分数据 的计算，也就是说产生数据倾斜的 HQL 中一定存在分组操作，那么从 HQL 的角度，我们可 以将数据倾斜分为单表携带了 GroupBy 字段的查询和两表（或者多表）Join 的查询。</p>
<h3 id="4-1-单表数据倾斜优化"><a href="#4-1-单表数据倾斜优化" class="headerlink" title="4.1 单表数据倾斜优化"></a>4.1 单表数据倾斜优化</h3><h4 id="4-1-1-使用参数"><a href="#4-1-1-使用参数" class="headerlink" title="4.1.1 使用参数"></a>4.1.1 使用参数</h4><p>​    当任务中存在 GroupBy 操作同时聚合函数为 count 或者 sum 可以设置参数来处理数据 倾斜问题。</p>
<pre class=" language-sql"><code class="language-sql"><span class="token comment" spellcheck="true">-- 是否在 Map 端进行聚合，默认为 True</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>map<span class="token punctuation">.</span>aggr <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token comment" spellcheck="true">-- 在 Map 端进行聚合操作的条目数目</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>mapaggr<span class="token punctuation">.</span>checkinterval <span class="token operator">=</span> <span class="token number">100000</span><span class="token punctuation">;</span>
</code></pre>
<p>有数据倾斜的时候进行负载均衡（默认是 false）</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>groupby<span class="token punctuation">.</span>skewindata <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre>
<p>当选项设定为 true，生成的查询计划会有两个 MR Job。</p>
<h4 id="4-1-2-增加-Reduce-数量（多个-Key-同时导致数据倾斜）"><a href="#4-1-2-增加-Reduce-数量（多个-Key-同时导致数据倾斜）" class="headerlink" title="4.1.2 增加 Reduce 数量（多个 Key 同时导致数据倾斜）"></a>4.1.2 增加 Reduce 数量（多个 Key 同时导致数据倾斜）</h4><p>1）调整 reduce 个数方法一</p>
<p>（1）每个 Reduce 处理的数据量默认是 256MB</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>bytes<span class="token punctuation">.</span>per<span class="token punctuation">.</span>reducer <span class="token operator">=</span> <span class="token number">256000000</span>
</code></pre>
<p>（2）每个任务最大的 reduce 数，默认为 1009</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>max <span class="token operator">=</span> <span class="token number">1009</span>
</code></pre>
<p>（3）计算 reducer 数的公式</p>
<pre class=" language-sql"><code class="language-sql">N<span class="token operator">=</span><span class="token function">min</span><span class="token punctuation">(</span>参数 <span class="token number">2</span>，总输入数据量<span class="token operator">/</span>参数 <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">(</span>参数 <span class="token number">2</span> 指的是上面的 <span class="token number">1009</span>，参数 <span class="token number">1</span> 值得是 256M<span class="token punctuation">)</span>
</code></pre>
<p>2）调整 reduce 个数方法二</p>
<p>在 hadoop 的 mapred-default.xml 文件中修改</p>
<p>设置每个 job 的 Reduce 个数</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces <span class="token operator">=</span> <span class="token number">15</span><span class="token punctuation">;</span>
</code></pre>
<h3 id="4-2-Join-数据倾斜优化"><a href="#4-2-Join-数据倾斜优化" class="headerlink" title="4.2 Join 数据倾斜优化"></a>4.2 Join 数据倾斜优化</h3><h4 id="4-2-1-使用参数"><a href="#4-2-1-使用参数" class="headerlink" title="4.2.1 使用参数"></a>4.2.1 使用参数</h4><p>​    在编写 Join 查询语句时，如果确定是由于 join 出现的数据倾斜，那么请做如下设置：</p>
<pre class=" language-sql"><code class="language-sql"><span class="token comment" spellcheck="true"># join 的键对应的记录条数超过这个值则会进行分拆，值根据具体数据量设置</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span>skewjoin<span class="token punctuation">.</span><span class="token keyword">key</span><span class="token operator">=</span><span class="token number">100000</span><span class="token punctuation">;</span>
<span class="token comment" spellcheck="true"># 如果是 join 过程出现倾斜应该设置为 true</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">optimize</span><span class="token punctuation">.</span>skewjoin<span class="token operator">=</span><span class="token boolean">false</span><span class="token punctuation">;</span>
</code></pre>
<p>如果开启了，在 Join 过程中 Hive 会将计数超过阈值 hive.skewjoin.key（默认 100000）的 倾斜 key 对应的行临时写进文件中，然后再启动另一个 job 做 map join 生成结果。通过 hive.skewjoin.mapjoin.map.tasks 参数还可以控制第二个 job 的 mapper 数量，默认 10000。</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>skewjoin<span class="token punctuation">.</span>mapjoin<span class="token punctuation">.</span>map<span class="token punctuation">.</span>tasks<span class="token operator">=</span><span class="token number">10000</span><span class="token punctuation">;</span>
</code></pre>
<h4 id="4-2-2-MapJoin"><a href="#4-2-2-MapJoin" class="headerlink" title="4.2.2 MapJoin"></a>4.2.2 MapJoin</h4><p>详情见 3.8 节</p>
<h2 id="第-5-章-Hive-Job-优化"><a href="#第-5-章-Hive-Job-优化" class="headerlink" title="第 5 章 Hive Job 优化"></a>第 5 章 Hive Job 优化</h2><h3 id="5-1-Hive-Map-优化"><a href="#5-1-Hive-Map-优化" class="headerlink" title="5.1 Hive Map 优化"></a>5.1 Hive Map 优化</h3><h4 id="5-1-1-复杂文件增加-Map-数"><a href="#5-1-1-复杂文件增加-Map-数" class="headerlink" title="5.1.1 复杂文件增加 Map 数"></a>5.1.1 复杂文件增加 Map 数</h4><p>​    当 input 的文件都很大，任务逻辑复杂，map 执行非常慢的时候，可以考虑增加 Map 数，来使得每个 map 处理的数据量减少，从而提高任务的执行效率。增加 map 的方法为：根据<br>$$<br>computeSliteSize(Math.max(minSize,Math.min(maxSize,blocksize)))=blocksize=128M<br>$$<br>调整 maxSize 最大值。让 maxSize 最大值低于 blocksize 就可以增加 map 的个数。</p>
<p>1）执行查询</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre>
<p>2）设置最大切片值为 100 个字节</p>
<pre class=" language-sql"><code class="language-sql"> <span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>input<span class="token punctuation">.</span>fileinputformat<span class="token punctuation">.</span>split<span class="token punctuation">.</span>maxsize<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">;</span>
 <span class="token keyword">select</span> <span class="token function">count</span><span class="token punctuation">(</span><span class="token operator">*</span><span class="token punctuation">)</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
</code></pre>
<h4 id="5-1-2-小文件进行合并"><a href="#5-1-2-小文件进行合并" class="headerlink" title="5.1.2 小文件进行合并"></a>5.1.2 小文件进行合并</h4><p>1）在 map 执行前合并小文件，减少 map 数：CombineHiveInputFormat 具有对小文件进行合 并的功能（系统默认的格式）。HiveInputFormat 没有对小文件合并功能。</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>input<span class="token punctuation">.</span>format<span class="token operator">=</span> org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>hadoop<span class="token punctuation">.</span>hive<span class="token punctuation">.</span>ql<span class="token punctuation">.</span>io<span class="token punctuation">.</span>CombineHiveInputFormat<span class="token punctuation">;</span>
</code></pre>
<p>2）在 Map-Reduce 的任务结束时合并小文件的设置：</p>
<p>在 map-only 任务结束时合并小文件，默认 true</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>mapfiles <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre>
<p>在 map-reduce 任务结束时合并小文件，默认 false</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>mapredfiles <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>
</code></pre>
<p>合并文件的大小，默认 256M</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>size<span class="token punctuation">.</span>per<span class="token punctuation">.</span>task <span class="token operator">=</span> <span class="token number">268435456</span><span class="token punctuation">;</span>
</code></pre>
<p>当输出文件的平均大小小于该值时，启动一个独立的 map-reduce 任务进行文件 merge</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">merge</span><span class="token punctuation">.</span>smallfiles<span class="token punctuation">.</span>avgsize <span class="token operator">=</span> <span class="token number">16777216</span><span class="token punctuation">;</span>
</code></pre>
<h4 id="5-1-3-Map-端聚合"><a href="#5-1-3-Map-端聚合" class="headerlink" title="5.1.3 Map 端聚合"></a>5.1.3 Map 端聚合</h4><pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>map<span class="token punctuation">.</span>aggr<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">-- 相当于 map 端执行 combiner</span>
</code></pre>
<h4 id="5-1-4-推测执行"><a href="#5-1-4-推测执行" class="headerlink" title="5.1.4 推测执行"></a>5.1.4 推测执行</h4><pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> mapred<span class="token punctuation">.</span>map<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>speculative<span class="token punctuation">.</span>execution <span class="token operator">=</span> <span class="token boolean">true</span><span class="token punctuation">;</span>  <span class="token comment" spellcheck="true">-- #默认是 true</span>
</code></pre>
<h3 id="5-2-Hive-Reduce-优化"><a href="#5-2-Hive-Reduce-优化" class="headerlink" title="5.2 Hive Reduce 优化"></a>5.2 Hive Reduce 优化</h3><h4 id="5-2-1-合理设置-Reduce-数"><a href="#5-2-1-合理设置-Reduce-数" class="headerlink" title="5.2.1 合理设置 Reduce 数"></a>5.2.1 合理设置 Reduce 数</h4><p>1）调整 reduce 个数方法一</p>
<p>（1）每个 Reduce 处理的数据量默认是 256MB</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>bytes<span class="token punctuation">.</span>per<span class="token punctuation">.</span>reducer <span class="token operator">=</span> <span class="token number">256000000</span>
</code></pre>
<p>（2）每个任务最大的 reduce 数，默认为 1009</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>reducers<span class="token punctuation">.</span>max <span class="token operator">=</span> <span class="token number">1009</span>
</code></pre>
<p>（3）计算 reducer 数的公式<br>$$<br>N=min(参数 2，总输入数据量/参数 1)(参数 2 指的是上面的 1009，参数 1 值得是 256M)<br>$$<br>2）调整 reduce 个数方法二</p>
<p>​    在 hadoop 的 mapred-default.xml 文件中修改 设置每个 job 的 Reduce 个数</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> mapreduce<span class="token punctuation">.</span>job<span class="token punctuation">.</span>reduces <span class="token operator">=</span> <span class="token number">15</span><span class="token punctuation">;</span>
</code></pre>
<p>3）reduce 个数并不是越多越好</p>
<p>（1）过多的启动和初始化 reduce 也会消耗时间和资源； </p>
<p>（2）另外，有多少个 reduce，就会有多少个输出文件，如果生成了很多个小文件，那 么如果这些小文件作为下一个任务的输入，则也会出现小文件过多的问题； 在设置 reduce 个数的时候也需要考虑这两个原则：处理大数据量利用合适的 reduce 数； 使单个 reduce 任务处理数据量大小要合适；</p>
<h4 id="5-2-2-推测执行"><a href="#5-2-2-推测执行" class="headerlink" title="5.2.2  推测执行"></a>5.2.2  推测执行</h4><pre class=" language-sql"><code class="language-sql">mapred<span class="token punctuation">.</span>reduce<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>speculative<span class="token punctuation">.</span>execution （hadoop 里面的）
hive<span class="token punctuation">.</span>mapred<span class="token punctuation">.</span>reduce<span class="token punctuation">.</span>tasks<span class="token punctuation">.</span>speculative<span class="token punctuation">.</span>execution（hive 里面相同的参数，效果和hadoop 里面的一样两个随便哪个都行）
</code></pre>
<h3 id="5-3-Hive-任务整体优化"><a href="#5-3-Hive-任务整体优化" class="headerlink" title="5.3 Hive 任务整体优化"></a>5.3 Hive 任务整体优化</h3><h4 id="5-3-1-Fetch-抓取"><a href="#5-3-1-Fetch-抓取" class="headerlink" title="5.3.1 Fetch 抓取"></a>5.3.1 Fetch 抓取</h4><p>​    Fetch 抓取是指，Hive 中对某些情况的查询可以不必使用 MapReduce 计算。</p>
<p>​    例如：SELECT * FROM emp;在这种情况下，Hive 可以简单地读取 emp 对应的存储目录下的文件，然后输出 查询结果到控制台。 </p>
<p>​    在 hive-default.xml.template 文件中 hive.fetch.task.conversion 默认是 more，老版本 hive 默认是 minimal，该属性修改为 more 以后，在全局查找、字段查找、limit 查找等都不走</p>
<p>mapreduce。</p>
<pre class=" language-xml"><code class="language-xml"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>property</span><span class="token punctuation">></span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>name</span><span class="token punctuation">></span></span>hive.fetch.task.conversion<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>name</span><span class="token punctuation">></span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>value</span><span class="token punctuation">></span></span>more<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>value</span><span class="token punctuation">></span></span>
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>description</span><span class="token punctuation">></span></span>
     期望一个[没有，最少，更多]。  
    一些选择查询可以转换为单个FETCH任务最小化  
    延迟。  
    当前查询应该是单源的，没有任何子查询  
    不应该有任何聚合或区别(这会导致RS)，  
    侧面视图和连接。  
    0.  无:关闭hive.fetch.task.conversion  
    1.  最小:SELECT STAR，对分区列进行过滤，仅限  
    2.  more: SELECT, FILTER, LIMIT only(支持TABLESAMPLE和  虚拟列)  
 <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>description</span><span class="token punctuation">></span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>property</span><span class="token punctuation">></span></span>
</code></pre>
<p>1）案例实操：</p>
<p>（1）把 hive.fetch.task.conversion 设置成 none，然后执行查询语句，都会执行 mapreduce 程序。</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span>task<span class="token punctuation">.</span>conversion<span class="token operator">=</span>none<span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
<span class="token keyword">select</span> ename <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
<span class="token keyword">select</span> ename <span class="token keyword">from</span> emp <span class="token keyword">limit</span> <span class="token number">3</span><span class="token punctuation">;</span>
</code></pre>
<p>（2）把 hive.fetch.task.conversion 设置成 more，然后执行查询语句，如下查询方式都不 会执行 mapreduce 程序。</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">fetch</span><span class="token punctuation">.</span>task<span class="token punctuation">.</span>conversion<span class="token operator">=</span>more<span class="token punctuation">;</span>
<span class="token keyword">select</span> <span class="token operator">*</span> <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
<span class="token keyword">select</span> ename <span class="token keyword">from</span> emp<span class="token punctuation">;</span>
<span class="token keyword">select</span> ename <span class="token keyword">from</span> emp <span class="token keyword">limit</span> <span class="token number">3</span><span class="token punctuation">;</span>
</code></pre>
<h4 id="5-3-2-本地模式"><a href="#5-3-2-本地模式" class="headerlink" title="5.3.2 本地模式"></a>5.3.2 本地模式</h4><p>​    大多数的 Hadoop Job 是需要 Hadoop 提供的完整的可扩展性来处理大数据集的。</p>
<p>​    不过， 有时 Hive 的输入数据量是非常小的。在这种情况下，为查询触发执行任务消耗的时间可能 会比实际 job 的执行时间要多的多。对于大多数这种情况，Hive 可以通过本地模式在单台机 器上处理所有的任务。</p>
<p>​    对于小数据集，执行时间可以明显被缩短。 用户可以通过设置 hive.exec.mode.local.auto 的值为 true，来让 Hive 在适当的时候自动 启动这个优化。</p>
<pre class=" language-xml"><code class="language-xml">set hive.exec.mode.local.auto=true; //开启本地 mr
//设置 local mr 的最大输入数据量，当输入数据量小于这个值时采用 local mr 的方式，默认为 134217728，即 128M
set hive.exec.mode.local.auto.inputbytes.max=50000000;
//设置 local mr 的最大输入文件个数，当输入文件个数小于这个值时采用 local mr 的方式，默认为 4
set hive.exec.mode.local.auto.input.files.max=10;
</code></pre>
<p>1）案例实操：</p>
<p>（1）开启本地模式，并执行查询语句</p>
<pre class=" language-xml"><code class="language-xml">set hive.exec.mode.local.auto=true;
select * from emp cluster by deptno;
</code></pre>
<p>（2）关闭本地模式，并执行查询语句</p>
<pre class=" language-xml"><code class="language-xml">set hive.exec.mode.local.auto=false;
select * from emp cluster by deptno;
</code></pre>
<h4 id="5-3-3-并行执行"><a href="#5-3-3-并行执行" class="headerlink" title="5.3.3 并行执行"></a>5.3.3 并行执行</h4><p>​    Hive 会将一个查询转化成一个或者多个阶段。</p>
<p>​    这样的阶段可以是 MapReduce 阶段、抽 样阶段、合并阶段、limit 阶段。</p>
<p>​    或者 Hive 执行过程中可能需要的其他阶段。默认情况下， Hive 一次只会执行一个阶段。不过，某个特定的 job 可能包含众多的阶段，而这些阶段可能 并非完全互相依赖的，也就是说有些阶段是可以并行执行的，这样可能使得整个 job 的执行 时间缩短。不过，如果有更多的阶段可以并行执行，那么 job 可能就越快完成。</p>
<p>通过设置参数 hive.exec.parallel 值为 true，就可以开启并发执行。不过，在共享集群中， 需要注意下，如果 job 中并行阶段增多，那么集群利用率就会增加。</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//打开任务并行执行，默认为 false</span>
<span class="token keyword">set</span> hive<span class="token punctuation">.</span><span class="token keyword">exec</span><span class="token punctuation">.</span>parallel<span class="token punctuation">.</span>thread<span class="token punctuation">.</span>number<span class="token operator">=</span><span class="token number">16</span><span class="token punctuation">;</span> <span class="token comment" spellcheck="true">//同一个 sql 允许最大并行度，默认为 8</span>
</code></pre>
<p>当然，得是在系统资源比较空闲的时候才有优势，否则，没资源，并行也起不来</p>
<p>(建议在数据量大,sql 很长的时候使用,数据量小,sql 比较的小开启有可能还不如之前快)。</p>
<h4 id="5-3-4-严格模式"><a href="#5-3-4-严格模式" class="headerlink" title="5.3.4 严格模式"></a>5.3.4 严格模式</h4><p>Hive 可以通过设置防止一些危险操作：</p>
<p>1）分区表不使用分区过滤</p>
<p>​    将 hive.strict.checks.no.partition.filter 设置为 true 时，对于分区表，除非 where 语句中含 有分区字段过滤条件来限制范围，否则不允许执行。换句话说，就是用户不允许扫描所有分 区。进行这个限制的原因是，通常分区表都拥有非常大的数据集，而且数据增加迅速。没有 进行分区限制的查询可能会消耗令人不可接受的巨大资源来处理这个表</p>
<p>2）使用 order by 没有 limit 过滤</p>
<p>​    将 hive.strict.checks.orderby.no.limit 设置为 true 时，对于使用了 order by 语句的查询，要 求必须使用 limit 语句。因为 order by 为了执行排序过程会将所有的结果数据分发到同一个 Reducer 中进行处理，强制要求用户增加这个 LIMIT 语句可以防止 Reducer 额外执行很长一段时间(开启了 limit 可以在数据进入到 reduce 之前就减少一部分数据)。</p>
<p>3）笛卡尔积</p>
<p>​    将 hive.strict.checks.cartesian.product 设置为 true 时，会限制笛卡尔积的查询。对关系型数 据库非常了解的用户可能期望在 执行 JOIN 查询的时候不使用 ON 语句而是使用 where 语 句，这样关系数据库的执行优化器就可以高效地将 WHERE 语句转化成那个 ON 语句。不幸 的是，Hive 并不会执行这种优化，因此，如果表足够大，那么这个查询就会出现不可控的情 况。</p>
<h4 id="5-3-5-JVM-重用"><a href="#5-3-5-JVM-重用" class="headerlink" title="5.3.5 JVM 重用"></a>5.3.5 JVM 重用</h4><p>​    小文件过多的时候使用。</p>
<h2 id="第-6-章-Hive-On-Spark"><a href="#第-6-章-Hive-On-Spark" class="headerlink" title="第 6 章 Hive On Spark"></a>第 6 章 Hive On Spark</h2><h3 id="6-1-Executor-参数"><a href="#6-1-Executor-参数" class="headerlink" title="6.1 Executor 参数"></a>6.1 Executor 参数</h3><p>​    以单台服务器 128G 内存，32 线程为例。</p>
<h4 id="6-1-1-spark-executor-cores"><a href="#6-1-1-spark-executor-cores" class="headerlink" title="6.1.1 spark.executor.cores"></a>6.1.1 spark.executor.cores</h4><p>​    该参数表示每个 Executor 可利用的 CPU 核心数。其值不宜设定过大，因为 Hive 的底层 以 HDFS 存储，而 HDFS 有时对高并发写入处理不太好，容易造成 竞争条件。根据经验 实践，设定在 3~6 之间比较合理。</p>
<p>​    假设我们使用的服务器单节点有 32 个 CPU 核心可供使用。考虑到系统基础服务和 HDFS 等组件的余量，一般会将 YARN NodeManager 的 yarn.nodemanager.resource.cpu-vcores 参数 设为 28，也就是 YARN 能够利用其中的 28 核，此时将 spark.executor.cores 设为 4 最合适， 最多可以正好分配给 7 个 Executor 而不造成浪费。又假设 yarn.nodemanager.resource.cpuvcores 为 26，那么将 spark.executor.cores 设为 5 最合适，只会剩余 1 个核。</p>
<p>​    由于一个 Executor 需要一个 YARN Container 来运行，所以还需保证 spark.executor.cores 的值不能大于单个 Container 能申请到的最大核心数，即 yarn.scheduler.maximum-allocationvcores 的值。</p>
<h4 id="6-1-2-spark-executor-memory-spark-yarn-executor-memoryOverhead"><a href="#6-1-2-spark-executor-memory-spark-yarn-executor-memoryOverhead" class="headerlink" title="6.1.2 spark.executor.memory/spark.yarn.executor.memoryOverhead"></a>6.1.2 spark.executor.memory/spark.yarn.executor.memoryOverhead</h4><p>​    这两个参数分别表示每个 Executor 可利用的堆内内存量和堆外内存量。堆内内存越大Executor 就能缓存更多的数据，在做诸如 map join 之类的操作时就会更快，但同时也会使得 GC 变得更麻烦。spark.yarn.executor.memoryOverhead 的默认值是 executorMemory * 0.10， 最小值为 384M(每个 Executor)</p>
<p>​    Hive 官方提供了一个计算 Executor 总内存量的经验公式，如下：</p>
<p>​    yarn.nodemanager.resource.memory-mb*(spark.executor.cores/ yarn.nodemanager.resource.cpu-vcores)</p>
<p>​    其实就是按核心数的比例分配。在计算出来的总内存量中，80%~85%划分给堆内内存， 剩余的划分给堆外内存。</p>
<p>​    假设集群中单节点有 128G 物理内存，yarn.nodemanager.resource.memory-mb（即单个 NodeManager 能够利用的主机内存量）设为 100G，那么每个 Executor 大概就是 100*(4/28)= 约 14G。</p>
<p>​    再 按 8:2 比 例 划 分 的 话 ， 最 终 spark.executor.memory 设 为 约 11.2G ， spark.yarn.executor.memoryOverhead 设为约 2.8G。</p>
<p>​    通过这些配置，每个主机一次可以运行多达 7 个 executor。每个 executor 最多可以运行 4 个 task(每个核一个)。因此，每个 task 平均有 3.5 GB(14 / 4)内存。在 executor 中运行的所 有 task 共享相同的堆空间。</p>
<pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> spark<span class="token punctuation">.</span>executor<span class="token punctuation">.</span>memory<span class="token operator">=</span><span class="token number">11</span><span class="token punctuation">.</span>2g<span class="token punctuation">;</span>
<span class="token keyword">set</span> spark<span class="token punctuation">.</span>yarn<span class="token punctuation">.</span>executor<span class="token punctuation">.</span>memoryOverhead<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">.</span>8g<span class="token punctuation">;</span>
</code></pre>
<p>同理，这两个内存参数相加的总量也不能超过单个 Container 最多能申请到的内存量， 即 yarn.scheduler.maximum-allocation-mb 配置的值。</p>
<h4 id="6-1-3-spark-executor-instances"><a href="#6-1-3-spark-executor-instances" class="headerlink" title="6.1.3 spark.executor.instances"></a>6.1.3 spark.executor.instances</h4><p>​    该参数表示执行查询时一共启动多少个 Executor 实例，这取决于每个节点的资源分配 情况以及集群的节点数。若我们一共有 10 台 32C/128G 的节点，并按照上述配置（即每个节 点承载 7 个 Executor），那么理论上讲我们可以将 spark.executor.instances 设为 70，以使集群 资源最大化利用。但是实际上一般都会适当设小一些（推荐是理论值的一半左右，比如 40）， 因为 Driver 也要占用资源，并且一个 YARN 集群往往还要承载除了 Hive on Spark 之外的其他 业务。</p>
<h4 id="6-1-4-spark-dynamicAllocation-enabled"><a href="#6-1-4-spark-dynamicAllocation-enabled" class="headerlink" title="6.1.4 spark.dynamicAllocation.enabled"></a>6.1.4 spark.dynamicAllocation.enabled</h4><p>​    上面所说的固定分配 Executor 数量的方式可能不太灵活，尤其是在 Hive 集群面向很多,用户提供分析服务的情况下。所以更推荐将 spark.dynamicAllocation.enabled 参数设为 true， 以启用 Executor 动态分配。</p>
<h4 id="6-1-5-参数配置样例参考"><a href="#6-1-5-参数配置样例参考" class="headerlink" title="6.1.5 参数配置样例参考"></a>6.1.5 参数配置样例参考</h4><pre class=" language-sql"><code class="language-sql"><span class="token keyword">set</span> hive<span class="token punctuation">.</span>execution<span class="token punctuation">.</span><span class="token keyword">engine</span><span class="token operator">=</span>spark<span class="token punctuation">;</span>
<span class="token keyword">set</span> spark<span class="token punctuation">.</span>executor<span class="token punctuation">.</span>memory<span class="token operator">=</span><span class="token number">11</span><span class="token punctuation">.</span>2g<span class="token punctuation">;</span>
<span class="token keyword">set</span> spark<span class="token punctuation">.</span>yarn<span class="token punctuation">.</span>executor<span class="token punctuation">.</span>memoryOverhead<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">.</span>8g<span class="token punctuation">;</span>
<span class="token keyword">set</span> spark<span class="token punctuation">.</span>executor<span class="token punctuation">.</span>cores<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> spark<span class="token punctuation">.</span>executor<span class="token punctuation">.</span>instances<span class="token operator">=</span><span class="token number">40</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> spark<span class="token punctuation">.</span>dynamicAllocation<span class="token punctuation">.</span>enabled<span class="token operator">=</span><span class="token boolean">true</span><span class="token punctuation">;</span>
<span class="token keyword">set</span> spark<span class="token punctuation">.</span>serializer<span class="token operator">=</span>org<span class="token punctuation">.</span>apache<span class="token punctuation">.</span>spark<span class="token punctuation">.</span>serializer<span class="token punctuation">.</span>KryoSerializer<span class="token punctuation">;</span>
</code></pre>
<h3 id="6-2-Driver-参数"><a href="#6-2-Driver-参数" class="headerlink" title="6.2 Driver 参数"></a>6.2 Driver 参数</h3><h4 id="6-2-1-spark-driver-cores"><a href="#6-2-1-spark-driver-cores" class="headerlink" title="6.2.1 spark.driver.cores"></a>6.2.1 spark.driver.cores</h4><p>​    该参数表示每个 Driver 可利用的 CPU 核心数。绝大多数情况下设为 1 都够用。</p>
<h4 id="6-2-2-spark-driver-memory-spark-driver-memoryOverhead"><a href="#6-2-2-spark-driver-memory-spark-driver-memoryOverhead" class="headerlink" title="6.2.2 spark.driver.memory/spark.driver.memoryOverhead"></a>6.2.2 spark.driver.memory/spark.driver.memoryOverhead</h4><p>​    这两个参数分别表示每个 Driver 可利用的堆内内存量和堆外内存量。根据资源富余程 度和作业的大小，一般是将总量控制在 512MB~4GB 之间，并且沿用 Executor 内存的“二八分 配方式”。例如，spark.driver.memory 可以设为约 819MB，spark.driver.memoryOverhead 设为 约 205MB，加起来正好 1G。</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">情深骚明</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://github.com/wmybigdata/2021/08/23/Hive%E9%AB%98%E7%BA%A7%E4%BC%98%E5%8C%96/">https://github.com/wmybigdata/2021/08/23/Hive%E9%AB%98%E7%BA%A7%E4%BC%98%E5%8C%96/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">情深骚明</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/hive/">
                                    <span class="chip bg-color">hive</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2021/08/24/Flink-%E5%AE%9E%E6%88%98%E6%95%99%E7%A8%8BCEP%E5%AE%9E%E6%88%98/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/15.jpg" class="responsive-img" alt="Flink-实战教程CEP实战">
                        
                        <span class="card-title">Flink-实战教程CEP实战</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            学习心得记录
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-08-24
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Flink%E6%B5%81%E5%BC%8F%E5%BC%95%E6%93%8E/" class="post-category">
                                    Flink流式引擎
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Flink%E6%B5%81%E5%BC%8F%E5%BC%95%E6%93%8E/">
                        <span class="chip bg-color">Flink流式引擎</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/08/23/Flink%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B%E4%BB%A5%E5%8F%8AFlinkdebug%E6%B5%81%E7%A8%8B%E5%88%86%E4%BA%AB/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/3.jpg" class="responsive-img" alt="Flink提交流程以及Flinkdebug流程分享">
                        
                        <span class="card-title">Flink提交流程以及Flinkdebug流程分享</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            学习心得记录
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-08-23
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/Flink%E6%B5%81%E5%BC%8F%E5%BC%95%E6%93%8E/" class="post-category">
                                    Flink流式引擎
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/Flink%E6%B5%81%E5%BC%8F%E5%BC%95%E6%93%8E/">
                        <span class="chip bg-color">Flink流式引擎</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2021</span>
            
            <span id="year">2019</span>
            <a href="/about" target="_blank">情深骚明</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/wmybigdata/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:wmy_2000@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2647716549" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2647716549" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>


    <a href="https://github.com/wmybigdata/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="https://github.com/wmybigdata/" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:wmy_2000@163.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2647716549" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2647716549" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>







    <a href="https://blog.csdn.net/weixin_45098163" class="tooltipped" target="_blank" data-tooltip="关注我的CSDN: https://blog.csdn.net/weixin_45098163" data-position="top" data-delay="50">
        <i class="fab fa-csdn">C</i>
    </a>




</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

	
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
